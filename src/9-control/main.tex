\input{../base.tex}

\begin{document}

%==================================================
\mynonumbersection{ОПТИМАЛЬНОЕ УПРАВЛЕНИЕ}

%==================================================
\mysection{Введение}

%========================================
\mysubsection{Динамика}

Начнём с рассмотрения обыкновенного дифференциального уравнения (ОДУ): \\

\myequation{
\begin{cases}
\dot{x}(t) = f(x(t)) & (t > 0) \\
x(0) = x^0 & \\
\end{cases}
}
\

В данном случае у нас есть начальная точка $x^0 \in \mathbb{R}^n$ и функция $f: \mathbb{R}^n  \rightarrow \mathbb{R}^n$. Неизвестным является кривая $x: [0, \infty) \rightarrow \mathbb{R}^n$, которую мы интерпретируем как динамическую эволюцию состояния некоторой системы. \\

%========================================
\mysubsection{Контролируемая динамика}

Мы немного обобщим и предположим, что теперь функция $f$ также зависит от некоторых ``контролирующих'' параметров принадлежащих множеству $A \subset \mathbb{R}^m$, так чтобы $f: \mathbb{R}^n \times A \rightarrow \mathbb{R}^n$. Тогда, если мы выберем некоторый элемент $a \in A$ и рассмотрим динамику: \\

\myequation{
\begin{cases}
\dot{x}(t) = f(x(t), a) & (t > 0) \\
x(0) = x^0, & \\
\end{cases}
}
\

мы получим эволюцию нашей системы в ситуации, когда параметр является константой равной $a$. \\

Далее мы можем изменять значение параметра вместе с изменением системы. Определим функцию $\alpha: [0, \infty) \rightarrow A$, называемую контролем. В таком случае мы получаем следующее ОДУ: \\

\myequation{
\begin{cases}
\dot{x}(t) = f(x(t), \alpha(t)) & (t > 0) \\
x(0) = x^0, & \\
\end{cases}
}
\

при этом траекторию $x(\cdot)$ мы будем воспринимать как ответ системы. \\

%========================================
\mysubsection{Нотация}

Мы будем писать: \\

\myequation{f(x,a) = \begin{pmatrix} f^1(x,a) \\ \vdots \\ f^n(x,a) \end{pmatrix} , }
\

чтобы изобразить компоненты $f$, аналогично: \\

\myequation{x(t) = \begin{pmatrix} x^1(t) \\ \vdots \\ x^n(t) \end{pmatrix} .}
\

Мы также обозначим: \\

\myequation{\mathbb{A} = \{ \alpha: [0, \infty) \rightarrow A \, | \, \alpha(\cdot) \, \text{измерима} \} ,}
\

чтобы обозначить множество всех возможных допустимых контролей, где: \\

\myequation{\alpha(t) = \begin{pmatrix} \alpha^1(t) \\ \vdots \\ \alpha^m(t) \end{pmatrix} .}
\

Обратите внимание, что решение ОДУ $x(\cdot)$ зависит от $\alpha(\cdot)$ и начальных условий. Поэтому, строго говоря, мы бы должны были писать $x(\cdot) = x(\cdot, \alpha(\cdot), x^0)$, чтобы отразить зависимость ответа системы $x(\cdot)$ от контроля и начального значения. \\

%========================================
\mysubsection{Награда}

Наша общая задача будет определить ``наилучший'' контроль для нашей системы. Для этого нам потребуется ввести специальный функционал награды: \\

\myequation{P[\alpha(\cdot)] := \int_0^T r(x(t), \alpha(t))dt + g(x(T)) ,}
\

где $x(\cdot)$ решает ОДУ для контроля $\alpha(\cdot)$. Здесь $r: \mathbb{R}^n \times A \rightarrow \mathbb{R}$ и $g: \mathbb{R}^n \rightarrow \mathbb{R}$ заданы, и $r$ называется скользящей наградой, а $g$ – конечной наградой. Конечное время $T > 0$ также задано. \\

%========================================
\mysubsection{Постановка задачи}

Нашей целью является нахождение контроля $\alpha^*(\cdot)$, который максимизирует награду. Другими словами мы хотим, чтобы: \\

\myequation{P[\alpha^*(\cdot)] \geq P[\alpha(\cdot)] }
\

для любого контроля $\alpha(\cdot) \in \mathbb{A}$. Такой контроль $\alpha^*(\cdot)$ называется оптимальным. \\

Такая задача ставит перед нами несколько математических вопросов: \\

\begin{enumerate}
  \item Существует-ли оптимальный контроль?
  \item Как мы можем математически характеризовать оптимальный контроль?
  \item Как мы можем построить оптимальный контроль?
\end{enumerate}
\

%==================================================
\mysection{Примеры}

%========================================
\mysubsection{Контроль производства и потребления}

Допустим, мы владеем заводом, чью продукцию мы можем контролировать. Начнем с построения математической модели, положив: \\

\myequation{x(t) = \text{количество продукции, произведенной в момент времени } t \geq 0.}
\

Мы предположим, что мы потребляем какую-то долю продукции в каждый момент времени, и также повторно используем оставшуюся часть продукции. Обозначим: \\

\myequation{\alpha(t) = \text{доля повторно использованной продукции в момент времени } t \geq 0.}
\

Это будет нашим контролем, для которого есть естественные ограничения: \\

\myequation{0 \leq \alpha(t) \leq 1 \text{ в каждый в момент времени } t \geq 0.}
\

Имея такой контроль, соответствующая динамика описывается ОДУ: \\

\myequation{
\begin{cases}
\dot{x}(t) = k \alpha(t) x(t) \\
x(0) = x^0. \\
\end{cases}
}
\

константа $k > 0$ моделирует скорость роста нашего повторного использования. Рассмотрим следующий функционал награды: \\

\myequation{P[\alpha(\cdot)] := \int_0^T (1 - \alpha(t))x(t)dt.}
\

Смысл в том, что мы хотим максимизировать наше общее потребление продукции, при учёте того, что наше потребление в момент времени $t$ равно $(1 - \alpha(t))x(t)$. Эта модель соответствует нашей общей постановке для $n = m = 1$, если мы примем: \\

\myequation{\mathbb{A} = [0, 1], f(x,a) = kax, r(x, a) = (1 - a)x, g \equiv 0}
\

Как мы потом выясним, оптимальный контроль $\alpha^*(\cdot)$ задается \textbf{переключением}: \\

\myequation{\alpha^*(\cdot) = 
\begin{cases}
1 & \text{, если } 0 \leq t \leq t^* \\
0 & \text{, если } t^* < t \leq T \\
\end{cases}
}
\

%========================================
\mysubsection{Маятник}

Рассмотрим маятник, для которого: \\

\myequation{\theta(t) = \text{угол в момент времени } t.}
\

Если внешние силы отсутствуют, то у нас есть следующие уравнения движения: \\

\myequation{
\begin{cases}
\ddot{\theta}(t) + \lambda \dot{\theta}(t) + \omega^2 \theta(t) = 0 \\
\theta(0) = \theta_1, \dot{\theta}(0) = \theta_2;
\end{cases}
}
\

решением которых являются затухающие колебания, при условии $\lambda > 0$. \\

Теперь введем крутящий момент $\alpha(\cdot)$, для которого есть физическое ограничение: \\

\myequation{|\alpha| \leq 1}
\

Тогда наша динамика становится: \\

\myequation{
\begin{cases}
\ddot{\theta}(t) + \lambda \dot{\theta}(t) + \omega^2 \theta(t) = \alpha(t) \\
\theta(0) = \theta_1, \dot{\theta}(0) = \theta_2;
\end{cases}
}
\

Определим $x_1(t) = \theta(t), x_2(t) = \dot{\theta}(t)$ и $x(t) = (x_1(t), x_2(t))$. Тогда мы можем записать эволюцию нашей системы как: \\

\myequation{\dot{x}(t) = \begin{pmatrix} \dot{x}_1 \\ \dot{x}_2 \end{pmatrix} = \begin{pmatrix} \dot{\theta} \\ \ddot{\theta} \end{pmatrix} = \begin{pmatrix} x_2 \\ -\lambda x_2 - \omega^2 x_1 + \alpha(t) \end{pmatrix} = f(x, \alpha) .}
\

Мы также введём: \\

\myequation{P[\alpha(\cdot)] = -\int_0^\tau 1dt = -\tau,}
\

для: \\

\myequation{\tau = \tau(\alpha(\cdot)) = \text{первый момент, когда } x(\tau) = 0 }
\

Мы хотим максимизировать $P[\cdot]$, тем самым мы хотим минимизировать время, за которое маятник придет в спокойствие. \\

%==================================================
\mysection{Линейный оптимальный контроль}

%========================================
\mysubsection{Существование оптимального контроля}

Рассмотрим ОДУ: \\

\myequation{
\begin{cases}
\dot{x}(t) = Mx(t) + N\alpha(t) \\
x(0) = x^0,
\end{cases}
}
\

для данных матриц $M \in \mathbb{M}^{n \times n}$ и $N \in \mathbb{M}^{n \times m}$. Обозначим за $\mathbb{A}$ куб $[-1, 1]^m \subset \mathbb{R}^m$. Определим: \\

\myequation{P[\alpha(\cdot)] = -\int_0^\tau 1dt = -\tau,}
\

где $\tau = \tau(\alpha(\cdot))$ обозначает первый момент, когда ОДУ доходит до 0. Если траектория никогда не доходит до 0, то $\tau = \infty$. \\

%========================================
\mysubsection{Задача оптимального контроля}

Нам дана начальная точка $x^0 \in \mathbb{R}^n$, и мы хотим найти оптимальный контроль $\alpha^*(\cdot)$ такой, что: \\

\myequation{P[\alpha^*(\cdot)] = \max_{\alpha(\cdot) \in \mathbb{A}} P[\alpha(\cdot)] .}
\

Тогда: \\

\myequation{\tau^* = - \rho[\alpha^*(\cdot)] \text{это минимальное время для касания нуля.} }
\

\mytheorem{\textbf{Существование оптимального контроля.} Пусть $x^0 \in \mathbb{R}^n$. Тогда существует оптимальное переключение $\alpha^*(\cdot)$. }
\

%========================================
\mysubsection{Принцип максимума для оптимального контроля}

Действительно интересная практическая задача теперь понять, как вычислить оптимальный контроль $\alpha^*(\cdot)$. \\

\mydefinition{Определим $K(t,x^0)$ как множество достижимости в момент времени $t$. То есть $K(t,x^0) = \{ x^1 \, | $ существует $\alpha(\cdot) \in \mathbb{A}$, которое переключает из $x^0$ в $x^1$ в момент времени $t \}$ .}
\

Так как $x(\cdot)$ решает ОДУ, то $x^1 \in K(t,x^0)$ тогда и только тогда: \\

\myequation{x^1 = X(t)x^0 + X(t) \int_0^t X^{-1} N \alpha(s) ds = x(t)}
\

для некоторого контроля $\alpha(\cdot) \in \mathbb{A}$. \\

\mytheorem{\textbf{Геометрия множества $K$}. Множество $K(t,x^0)$ выпуклое и замкнутое.}
\

\mytheorem{\textbf{Принцип максимума Понтрягина}. Существует ненулевой вектор $h$ такой, что \myequation{h^T X^{-1}(t) N \alpha^*(t) = \max_{a \in \mathbb{A}} \{ h^T X^{-1} N a \} } для каждого момента времени $0 \leq t \leq \tau^*$.} 
\

\mytheorem{\textbf{Принцип максимума Понтрягина в сопряженной форме}. Пусть $\alpha^*(\cdot)$ это оптимальный контроль, и $x^*(\cdot)$ это соответсвующий ему ответ. Тогда существует функция $p^*(\cdot): [0, \tau^*] \rightarrow \mathbb{R}^n$ такая, что \myequation{\dot{x}^*(t) = \bigtriangledown_p H(x^*(t), p^*(t), \alpha^*(t)) } \myequation{\dot{p}^*(t) = -\bigtriangledown_x H(x^*(t), p^*(t), \alpha^*(t)) } \myequation{H(x^*(t), p^*(t), \alpha^*(t)) = \max_{a \in \mathbb{A}} H(x^*(t), p^*(t), a) }. }
\

\end{document}
